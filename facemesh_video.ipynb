{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize FaceMesh and drawing utilities\n",
    "# mp_facemesh = mp.solutions.face_mesh\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "\n",
    "# # Define constants for drowsiness detection\n",
    "# EAR_THRESHOLD = 0.2  # Threshold for Eye Aspect Ratio to detect drowsiness\n",
    "# EAR_CONSEC_FRAMES = 15  # Number of consecutive frames the person must be below the threshold for drowsiness\n",
    "\n",
    "# # Landmark points for eyes\n",
    "# chosen_left_eye_idxs = [362, 385, 387, 263, 373, 380]\n",
    "# chosen_right_eye_idxs = [33, 160, 158, 133, 153, 144]\n",
    "# all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n",
    "# # Function to calculate Euclidean distance\n",
    "# def distance(point_1, point_2):\n",
    "#     return sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "\n",
    "# # Function to calculate Eye Aspect Ratio (EAR)\n",
    "# def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "#     try:\n",
    "#         coords_points = []\n",
    "#         for i in refer_idxs:\n",
    "#             lm = landmarks[i]\n",
    "#             coord = denormalize_coordinates(lm.x, lm.y, frame_width, frame_height)\n",
    "#             coords_points.append(coord)\n",
    "\n",
    "#         # Eye landmark (x, y)-coordinates\n",
    "#         P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "#         P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "#         P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "#         # Compute the eye aspect ratio\n",
    "#         ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "#     except:\n",
    "#         ear = 0.0\n",
    "#         coords_points = None\n",
    "\n",
    "#     return ear, coords_points\n",
    "\n",
    "# # Function to calculate average EAR for both eyes\n",
    "# def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "#     left_ear, _ = get_ear(landmarks, left_eye_idxs, image_w, image_h)\n",
    "#     right_ear, _ = get_ear(landmarks, right_eye_idxs, image_w, image_h)\n",
    "#     avg_ear = (left_ear + right_ear) / 2.0\n",
    "#     return avg_ear\n",
    "\n",
    "# # Open video file or capture device\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initialize FaceMesh with mediapipe\n",
    "# with mp_facemesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "#     frame_count = 0\n",
    "#     drowsy_frame_count = 0\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Convert the frame to RGB and process it with mediapipe\n",
    "#         image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         results = face_mesh.process(image_rgb)\n",
    "\n",
    "#         if results.multi_face_landmarks:\n",
    "#             landmarks = results.multi_face_landmarks[0].landmark\n",
    "#             imgH, imgW, _ = frame.shape\n",
    "\n",
    "#             # Calculate the average EAR for both eyes\n",
    "#             avg_ear = calculate_avg_ear(landmarks, chosen_left_eye_idxs, chosen_right_eye_idxs, imgW, imgH)\n",
    "\n",
    "#             # Check if the EAR is below the threshold for drowsiness\n",
    "#             if avg_ear < EAR_THRESHOLD:\n",
    "#                 drowsy_frame_count += 1\n",
    "#             else:\n",
    "#                 drowsy_frame_count = 0\n",
    "\n",
    "#             # If the person has been drowsy for a sufficient number of frames\n",
    "#             if drowsy_frame_count >= EAR_CONSEC_FRAMES:\n",
    "#                 label = \"Drowsy\"\n",
    "#                 color = (0, 0, 255)  # Red color for drowsiness\n",
    "#             else:\n",
    "#                 label = \"Awake\"\n",
    "#                 color = (0, 255, 0)  # Green color for awake\n",
    "\n",
    "#             # Overlay EAR score and label on the frame\n",
    "#             cv2.putText(frame, f\"EAR: {round(avg_ear, 2)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "#             cv2.putText(frame, label, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "#         # Show the frame with the overlay\n",
    "#         cv2.imshow('Drowsiness Detection', frame)\n",
    "\n",
    "#         # Break the loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     # Release the video capture object\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialize FaceMesh and drawing utilities\n",
    "# mp_facemesh = mp.solutions.face_mesh\n",
    "# mp_drawing = mp.solutions.drawing_utils\n",
    "# denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "\n",
    "# # Define constants for drowsiness detection\n",
    "# EAR_THRESHOLD = 0.2  # Threshold for Eye Aspect Ratio to detect drowsiness\n",
    "# EAR_CONSEC_FRAMES = 15  # Number of consecutive frames the person must be below the threshold for drowsiness\n",
    "\n",
    "# # Landmark points for eyes\n",
    "# chosen_left_eye_idxs = [362, 385, 387, 263, 373, 380]\n",
    "# chosen_right_eye_idxs = [33, 160, 158, 133, 153, 144]\n",
    "# all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n",
    "# # Function to calculate Euclidean distance\n",
    "# def distance(point_1, point_2):\n",
    "#     return sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "\n",
    "# # Function to calculate Eye Aspect Ratio (EAR)\n",
    "# def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "#     try:\n",
    "#         coords_points = []\n",
    "#         for i in refer_idxs:\n",
    "#             lm = landmarks[i]\n",
    "#             coord = denormalize_coordinates(lm.x, lm.y, frame_width, frame_height)\n",
    "#             coords_points.append(coord)\n",
    "\n",
    "#         # Eye landmark (x, y)-coordinates\n",
    "#         P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "#         P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "#         P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "#         # Compute the eye aspect ratio\n",
    "#         ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "#     except:\n",
    "#         ear = 0.0\n",
    "#         coords_points = None\n",
    "\n",
    "#     return ear, coords_points\n",
    "\n",
    "# # Function to calculate average EAR for both eyes\n",
    "# def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "#     left_ear, left_lm_coordinates = get_ear(landmarks, left_eye_idxs, image_w, image_h)\n",
    "#     right_ear, right_lm_coordinates = get_ear(landmarks, right_eye_idxs, image_w, image_h)\n",
    "#     avg_ear = (left_ear + right_ear) / 2.0\n",
    "#     return avg_ear, (left_lm_coordinates, right_lm_coordinates)\n",
    "\n",
    "# # Function to draw facemesh around the eyes\n",
    "# def draw_eye_landmarks(frame, eye_landmarks):\n",
    "#     for coord in eye_landmarks:\n",
    "#         if coord:  # Check if coordinate is not None\n",
    "#             cv2.circle(frame, coord, 2, (0, 255, 255), -1)  # Yellow color for eye landmarks\n",
    "\n",
    "# # Open video file or capture device\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Initialize FaceMesh with mediapipe\n",
    "# with mp_facemesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "#     frame_count = 0\n",
    "#     drowsy_frame_count = 0\n",
    "\n",
    "#     while cap.isOpened():\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "\n",
    "#         # Convert the frame to RGB and process it with mediapipe\n",
    "#         image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "#         results = face_mesh.process(image_rgb)\n",
    "\n",
    "#         if results.multi_face_landmarks:\n",
    "#             landmarks = results.multi_face_landmarks[0].landmark\n",
    "#             imgH, imgW, _ = frame.shape\n",
    "\n",
    "#             # Calculate the average EAR for both eyes\n",
    "#             avg_ear, (left_eye_coords, right_eye_coords) = calculate_avg_ear(\n",
    "#                 landmarks, chosen_left_eye_idxs, chosen_right_eye_idxs, imgW, imgH)\n",
    "\n",
    "#             # Check if the EAR is below the threshold for drowsiness\n",
    "#             if avg_ear < EAR_THRESHOLD:\n",
    "#                 drowsy_frame_count += 1\n",
    "#             else:\n",
    "#                 drowsy_frame_count = 0\n",
    "\n",
    "#             # If the person has been drowsy for a sufficient number of frames\n",
    "#             if drowsy_frame_count >= EAR_CONSEC_FRAMES:\n",
    "#                 label = \"Drowsy\"\n",
    "#                 color = (0, 0, 255)  # Red color for drowsiness\n",
    "#             else:\n",
    "#                 label = \"Awake\"\n",
    "#                 color = (0, 255, 0)  # Green color for awake\n",
    "\n",
    "#             # Overlay EAR score (in blue) and drowsiness/awake label on the frame\n",
    "#             cv2.putText(frame, f\"EAR: {round(avg_ear, 2)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)  # Blue color for EAR\n",
    "#             cv2.putText(frame, label, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "#             # Draw the facemesh around the eyes\n",
    "#             draw_eye_landmarks(frame, left_eye_coords)\n",
    "#             draw_eye_landmarks(frame, right_eye_coords)\n",
    "\n",
    "#         # Show the frame with the overlay\n",
    "#         cv2.imshow('Drowsiness Detection', frame)\n",
    "\n",
    "#         # Break the loop if 'q' is pressed\n",
    "#         if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "#             break\n",
    "\n",
    "#     # Release the video capture object\n",
    "#     cap.release()\n",
    "#     cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize FaceMesh and drawing utilities\n",
    "mp_facemesh = mp.solutions.face_mesh\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "denormalize_coordinates = mp_drawing._normalized_to_pixel_coordinates\n",
    "\n",
    "# Define constants for drowsiness detection\n",
    "EAR_THRESHOLD = 0.2  # Threshold for Eye Aspect Ratio to detect drowsiness\n",
    "EAR_CONSEC_FRAMES = 15  # Number of consecutive frames the person must be below the threshold for drowsiness\n",
    "\n",
    "# Landmark points for eyes\n",
    "chosen_left_eye_idxs = [362, 385, 387, 263, 373, 380]\n",
    "chosen_right_eye_idxs = [33, 160, 158, 133, 153, 144]\n",
    "all_chosen_idxs = chosen_left_eye_idxs + chosen_right_eye_idxs\n",
    "\n",
    "# Function to calculate Euclidean distance\n",
    "def distance(point_1, point_2):\n",
    "    return sum([(i - j) ** 2 for i, j in zip(point_1, point_2)]) ** 0.5\n",
    "\n",
    "# Function to calculate Eye Aspect Ratio (EAR)\n",
    "def get_ear(landmarks, refer_idxs, frame_width, frame_height):\n",
    "    try:\n",
    "        coords_points = []\n",
    "        for i in refer_idxs:\n",
    "            lm = landmarks[i]\n",
    "            coord = denormalize_coordinates(lm.x, lm.y, frame_width, frame_height)\n",
    "            coords_points.append(coord)\n",
    "\n",
    "        # Eye landmark (x, y)-coordinates\n",
    "        P2_P6 = distance(coords_points[1], coords_points[5])\n",
    "        P3_P5 = distance(coords_points[2], coords_points[4])\n",
    "        P1_P4 = distance(coords_points[0], coords_points[3])\n",
    "\n",
    "        # Compute the eye aspect ratio\n",
    "        ear = (P2_P6 + P3_P5) / (2.0 * P1_P4)\n",
    "\n",
    "    except:\n",
    "        ear = 0.0\n",
    "        coords_points = None\n",
    "\n",
    "    return ear, coords_points\n",
    "\n",
    "# Function to calculate average EAR for both eyes\n",
    "def calculate_avg_ear(landmarks, left_eye_idxs, right_eye_idxs, image_w, image_h):\n",
    "    left_ear, left_lm_coordinates = get_ear(landmarks, left_eye_idxs, image_w, image_h)\n",
    "    right_ear, right_lm_coordinates = get_ear(landmarks, right_eye_idxs, image_w, image_h)\n",
    "    avg_ear = (left_ear + right_ear) / 2.0\n",
    "    return avg_ear, (left_lm_coordinates, right_lm_coordinates)\n",
    "\n",
    "# Function to draw facemesh for the entire face in white\n",
    "def draw_facemesh(frame, landmarks, img_w, img_h):\n",
    "    for i, lm in enumerate(landmarks):\n",
    "        coord = denormalize_coordinates(lm.x, lm.y, img_w, img_h)\n",
    "        if coord:\n",
    "            # Draw the entire face landmarks in white\n",
    "            cv2.circle(frame, coord, 1, (255, 255, 255), -1)  # White color for face landmarks\n",
    "\n",
    "# Function to draw facemesh around the eyes in green\n",
    "def draw_eye_landmarks(frame, eye_landmarks):\n",
    "    for coord in eye_landmarks:\n",
    "        if coord:  # Check if coordinate is not None\n",
    "            cv2.circle(frame, coord, 2, (0, 255, 0), -1)  # Green color for eye landmarks\n",
    "\n",
    "# Open video file or capture device\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize FaceMesh with mediapipe\n",
    "with mp_facemesh.FaceMesh(max_num_faces=1, refine_landmarks=True, min_detection_confidence=0.5, min_tracking_confidence=0.5) as face_mesh:\n",
    "    frame_count = 0\n",
    "    drowsy_frame_count = 0\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Convert the frame to RGB and process it with mediapipe\n",
    "        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        results = face_mesh.process(image_rgb)\n",
    "\n",
    "        if results.multi_face_landmarks:\n",
    "            landmarks = results.multi_face_landmarks[0].landmark\n",
    "            imgH, imgW, _ = frame.shape\n",
    "\n",
    "            # Draw facemesh for the entire face in white\n",
    "            draw_facemesh(frame, landmarks, imgW, imgH)\n",
    "\n",
    "            # Calculate the average EAR for both eyes\n",
    "            avg_ear, (left_eye_coords, right_eye_coords) = calculate_avg_ear(\n",
    "                landmarks, chosen_left_eye_idxs, chosen_right_eye_idxs, imgW, imgH)\n",
    "\n",
    "            # Check if the EAR is below the threshold for drowsiness\n",
    "            if avg_ear < EAR_THRESHOLD:\n",
    "                drowsy_frame_count += 1\n",
    "            else:\n",
    "                drowsy_frame_count = 0\n",
    "\n",
    "            # If the person has been drowsy for a sufficient number of frames\n",
    "            if drowsy_frame_count >= EAR_CONSEC_FRAMES:\n",
    "                label = \"Drowsy\"\n",
    "                color = (0, 0, 255)  # Red color for drowsiness\n",
    "            else:\n",
    "                label = \"Awake\"\n",
    "                color = (0, 255, 0)  # Green color for awake\n",
    "\n",
    "            # Overlay EAR score (in blue) and drowsiness/awake label on the frame\n",
    "            cv2.putText(frame, f\"EAR: {round(avg_ear, 2)}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)  # Blue color for EAR\n",
    "            cv2.putText(frame, label, (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "\n",
    "            # Draw the facemesh around the eyes in green\n",
    "            draw_eye_landmarks(frame, left_eye_coords)\n",
    "            draw_eye_landmarks(frame, right_eye_coords)\n",
    "\n",
    "        # Show the frame with the overlay\n",
    "        cv2.imshow('Drowsiness Detection', frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    # Release the video capture object\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#08/09/2024 First Commit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
